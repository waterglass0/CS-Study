# 3. 운영체제(OS, Operationg System)
- 한정된 메모리나 시스템 자원을 효율적으로 분배함
- 사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스
- 펌웨어(firmware): 운영체제와 유사하지만 소프트웨어를 추가로 설치할 수 없는 것

<br>

# 3.1 운영체제와 컴퓨터
# 3.1.1 운영체제의 역할과 구조
## 운영체제의 역할
1. CPU 스케줄링과 프로세스 관리
- CPU 소유권을 프로세스에 할당
- 프로세스의 생성과 삭제
- 자원 할당 및 반환 관리
2. 메모리 관리
- 한정된 메모리를 어떤 프로세스에 얼마만큼 할당할지를 관리
3. 디스크 파일 관리
- 디스크 파일을 어떤 방법으로 보관할지 관리
4. I/O 디바이스 관리
- 마우스, 키보드 등의 I/O 디바이스와 컴퓨터 간에 데이터 이동을 관리

## 운영체제의 구조
|운영체제의 구조|
|---|
|유저 프로그램|
|GUI|
|시스템콜|
|커널|
|드라이버|
|하드웨어|
- 운영체제: GUI, 시스템콜, 커널, 드라이버 부분
- 리눅스 서버는 GUI가 없고 CUI만 있다
- `GUI`: 사용자 인터페이스의 한 형태. 단순 명령어 창이 아닌 아이콘을 마우스로 클릭하는 등의 단순한 동작으로 사용자가 컴퓨터와 상호작용할 수 있게 한다.
- `드라이버`: 하드웨어를 제어하기 위한 소프트웨어
- `CUI`: 그래픽이 아닌 명령어로 처리하는 인터페이스

### 시스템 콜

- 운영체제가 커널에 접근하기 전 거치는 인터페이스
- 프로세스나 스레드에서 운영체제로 어떠한 요청을 할 때 시스템콜이라는 인터페이스와 커널을 거쳐 운영체제에 전달됨
- 유저 프로그램이 I/O 요청으로 트랩 발동 -> 올바른 요청인지 확인 후 유저모드가 시스템콜을 통해 커널모드로 변환됨 -> 요청 수행 -> 다시 유저모드로 돌아가 그 뒤의 로직 수행
  - `I/O 요청`: 입출력 함수, 데이터베이스, 네트워크, 파일 접근 등에 관한 일
- 장점
  - 컴퓨터 자원에 대한 직접적인 접근을 차단할 수 있음
  - 프로그램을 다른 프로그램으로부터 보호할 수 있음
  - 네크워크 통신이나 데이터베이스와 같은 낮은 단계의 처리에 대한 부분을 많이 신경 쓰지 않고 프로그램을 구현할 수 있음

- `유저 모드`: 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부로 침범하지 못하는 모드
- `커널 모드`: 모든 컴퓨터 자원에 접근할 수 있는 모드
- `커널`
  - 운영체제의 핵심 부분이자 시스템콜 인터페이스를 제공
  - 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할을 한다.

  <br>

  #### modebit
  - 1 또는 0의 값을 가지는 플래그 변수
    - 0은 커널 모드, 1은 유저 모드
    - 유저 모두일 때는 시스템콜을 못하게 막아서 한정된 일만 할 수 있도록 한다.
  - 시스템콜이 작동될 때 modebit을 참고하여 유저 모드와 커널 모드를 구분한다.
  - I/O 디바이스를 운영체제를 통해서만 작동할 수 있도록 하여, 공격자의 공격을 막기가 쉽다.

<br>

# 3.1.2 컴퓨터의 요소
컴퓨터는 CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있다.

## CPU(Central Processing Unit)
- 산술논리연산장치, 제어장치, 레지스터로 구성되어있는 컴퓨터 장치
- 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행함
- 운영체제의 커널(관리자 역할)이 프로그램을 메모리에 올려 프로세스로 만듦 -> CPU(일꾼 역할)가 처리

### 제어장치(CU, Control Unit)
- 프로세스 조작을 지시하는 CPU의 한 부품
  - 입출력장치 간 통신 제어
  - 명령어를 읽고 해석
  - 데이터 처리를 위한 순서를 결정

### 레지스터
- **CPU 안에 있는 매우 빠른 임시기억장치**
- 연산 속도가 메모리보다 수십~수백배 빠르다
- CPU는 자체적으로 데이터를 저장하지 못하기 때문에, 레지스터를 거쳐 데이터를 전달한다.

### 산술논리연산장치(ALU, Arithmetic Logic Unit)
- 덧셈, 뺄셈 같은 숫자의 산술연산과 배타적 논리합, 논리곱 같은 논리 연산을 하는 디지털 회로

### CPU의 연산 처리
1. 제어장치가 계산할 값을 레지스터에 로드한다. 이어 레지스터에도 로드한다.
2. 제어장치가 산술논리연산장치에게 레지스터에 있는 값을 계산하도록 명령한다.
3. 계산된 값을 제어장치가 다시 레지스터에서 메모리로 저장한다.

### 인터럽트
- 어떤 신호가 들어왔을 때 CPU를 잠시 정지시키는 것
- I/O 디바이스, 0으로 숫자를 나누는 산술연산, 프로세스 오류 등으로 발생한다.
- 인터럽트가 발생면 인되터럽트 핸들러 함수가 모여있는 인터럽트 벡터로 가서 함수가 실행된다.
  - `인터럽트 핸들러 함수`: 인터럽트가 발생했을 때 이를 핸들링하기 위한 함수. 커널 내부의 IRQ를 통해 호출되며 request_irq()를 통해 인터럽트 핸들러 함수를 등록할 수 있다.
- 인터럽트 간에는 우선순위 존재

  #### 하드웨어 인터럽트
  - 키보드나 마우스를 연결하는 일 등의 I/O 디바이스에서 발생하는 인터럽트
  - 이때 순차적인 인터럽트 실행을 중지 -> 운영체제에 시스템콜을 요청 -> 원하는 디바이스에 있는 작은 로컬 버퍼에 접근하여 일 수행

  #### 소프트웨어 인터럽트
  - 트랩(trap)이라고도 함
  - 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동함

## DMA 컨트롤러
- I/O 디바이스가 메모리에 직접 접근할 수 있게 하는 하드웨어 장치
- CPU에만 너무 많은 인터럽트 요청이 들어가지 않도록한다. CPU의 부하를 막아주는 보조 일꾼.
- 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 막아준다.

## 메모리(memory)
- 전자회로에서 데이터, 상태, 명령어 등을 기록하는 장치
- 보통 RAM(Random Access Memory)을 일컬어 메모리라고 함
- CPU는 계산 담당, a메모리는 기억 담당
- 메모리가 클수록 많은 일을 동시에 할 수 있다.

## 타이머(timer)
- 특정 프로그램에 작업 시간 제한을 담

## 디바이스 컨트롤러(device controller)
- 컴퓨터와 연결되어 있는 I/O 디바이스의 작은 CPU

<br>

# 3.2 메모리
# 3.2.1 메모리 계층
|메모리 계층|
|---|
|레지스터|
|캐시|
|주기억장치|
|보조기억장치|
- 레지스터: **CPU 안에 있는 작은 메모리**
- 캐시: L1, L2 캐시를 지칭함. L3 캐시도 있다
- 주기억장치: RAM
  - 하드디스크로부터 일정량의 데이터를 복사해서 임시저장하고 이를 필요 시마다 CPU에 빠르게 전달함
    - 게임을 로딩할 때 이 과정을 수행한다.
- 보조기억장치: HDD, SSD
  - 위로 갈수록 속도가 빠르고 휘발성이 높으며 기억용량이 적다.
  - 위로 갈수록 가격이 비싸지는데, 이러한 경제성 때문에 계층을 두어 관리한다.

## 캐시(cache)
> 데이터를 미리 복사해 놓는 임시 저장소. 빠른 장치와 느린 장치 간 속도 차이에 의해 발생하는 병목 현상을 줄이기 위한 메모리
- 메모리와 CPU 사이의 속도 차이가 크기 때문에 그 중간에 레지스터 계층을 둔다. 이를 캐싱 계층이라고 함

### 지역성의 원리
- 캐시 계층을 두지 않고 캐시를 직접 설정할 때?
  - 자주 사용하는 데이터를 기반으로 설정한다.
  - 자주 사용하는 데이터를 찾는 근거는 지역성이다.

  #### 시간 지역성
  - 최근 사용한 데이터(변수 등)에 다시 접근하려는 특성
  #### 공간 지역성
  - 최근 접근한 데이터를 이루고 있는 공간 또는 가까운 공간에 접근하려는 특성

## 캐시히트와 캐시미스
- 캐시히트: 캐시에서 원하는 데이터를 찾아 가져오는 것
  - 위치가 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠르다
- 캐시미스: 원하는 데이터가 캐시에 없을 때 메모리로 가서 찾아오는 것
  - 시스템 버스를 기반으로 작동하기 때문에 느리다

### 캐시매핑
> 캐시가 히트되기 위해 매핑하는 방법
- 대표적으로 CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명한다.
  - RAM에 비해 레지스터의 용량은 매우 작기 때문에, 레지스터가 캐시 계층으로써 역할을 잘 하려면 캐시매핑을 어떻게 하는가가 중요하다.

|이름|설명|
|---|---|
|직접 매핑(directed mapping)|메모리와 캐시의 순서를 일치시킨다. 처리가 빠르지만 충돌이 잦다|
|연관 매핑(associative mapping)|순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑한다. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느리다.|
|집합 연관 매핑(set associative mapping)|직접 매핑과 연관 매핑을 합쳐 놓은 것. 순서는 일치시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색이 더 효율적이다|

### 웹 브라우저의 캐시
- 소프트웨어적인 캐시의 대표적인 예: 웹 브라우저의 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지
  - 보통 사용자의 커스텀 정보, 인증 모듈 관련 사항들을 웹 브라우저에 저장할 때 사용한다.
  - 추후 서버에 요청할 때 자신을 나타내는 아이덴티티로 사용하거나, 중복 요청을 방지한다.
  #### 쿠키
  > 만료기한이 있는 키-값 저장소
  - 설정에 따라 다른 도메인에서 요청했을 때 자동 전송된다
  - 4KB까지 데이터 저장 가능
  - 쿠키를 설정할 때는 옵션을 걸어 쿠키를 볼 수 없게 하는 것이 중요
  - 보통 클라이언트보다는 서버에서 만료기한을 정한다
  #### 로컬 스토리지
  > 만료기한이 없는 키-값 저장소
  - 10MB까지 저장 가능
  - 웹 브라우저를 닫아도 유지됨
  - 도메인 단위로 저장, 생성됨
  - HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없다
  - 클라이언트에서만 수정 가능
  #### 세션 스토리지
  > 만료기한이 없는 키-값 저장소
  - 탭 단위로 스토리지를 생성하며, 탭을 닫을 때 데이터가 삭제된다
  - 5MB까지 저장 가능
  - HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없다
  - 클라이언트에서만 수정 가능

### 데이터베이스의 캐싱 계층
데이터베이스 시스템을 구축할 때 성능을 향상시키기 위해, 메인 데이터베이스 위에 redis 데이터베이스를 **캐싱 계층**으로 둔다.
- 캐시히트: 앱이 redis로부터 데이터를 읽어오는 것
- 캐시미스: 앱이 메인 데이터베이스로부터 데이터를 읽어오는 것

<br>

# 3.2.2 메모리 관리
운영체제의 대표적인 역할로, 컴퓨터 내의 한정된 메모리를 최대한 효율적으로 활용하는 것

## 가상 메모리(virtual memory)
> 메모리 관리 기법의 하나로, 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 사용자 입장에서 매우 큰 메모리로 보이게 만드는 것 (캐시 역할)
- 이때 가상적으로 주어진 주소를 가상 주소(logical address), 실제 메모리상에 있는 주소를 실제 주소(physical address)라고 함
- 가상 주소는 메모리 관리 장치(MMU)에 의해 실제 주소로 변환된다.
  - -> 사용자는 프로그램을 구축할 때 실제 주소를 의식할 필요가 없다.
- 페이지 테이블로 관리됨
  - 페이지 테이블: 가상 주소와 실제 주소가 매핑되어 있다. 프로세스의 주소 정보가 들어있음
  - 이때 속도 향상을 위해 TLB를 쓴다
    - `TLB`: 메모리와 CPU 사이에서 주소변환을 위해 쓰이는 캐시. 속도를 향상시킨다. 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블에 가지 않도록 한다.

### 스와핑(swapping)
- 메모리에서 당장 사용하지 않는 영역을 하드디스크로 내리고, 필요할 때는 다시 RAM으로 올림을 반복하여 RAM을 효과적으로 관리하는 것
- 페이지 폴트를 방지한다.

### 페이지 폴트(page fault)
- 프로세스의 주소 공간에는 존재하나 현재 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생
- 발생하면 운영체제는 스와핑을 실행한다
1. CPU가 물리 메모리를 확인하고, 해당 페이지가 없으면 트랩을 발생시켜 운영체제에 알린다
2. 운영체제가 CPU의 동작을 일시정지한다
3. 운영체제가 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 찾는다.
  - 없으면 프로세스를 중단하고 현재 물리 메모리에 빈 프레임이 있는지 찾는다.
  - 물리 메모리에도 없으면 스와핑이 발동된다.
4. 비어 있는 프레임에 해당 페이지를 로드하고 페이지 테이블을 최신화한다.
5. 일시정지시켰던 CPU를 다시 시작한다.
- `페이지(page)`: 가상 메모리를 사용하는 최소 크기 단위
- `프레임(frame)`: 실제 메모리를 사용하는 최소 크기 단위

## 스래싱(thrashing)
> 메모리의 페이지 폴트 빈도가 높은 것. 이는 컴퓨터의 심각한 성능 저하를 불러온다.
-  메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나기 때문에 발생
  - 페이지 폴트가 일어나면 CPU 이용률이 낮아짐 -> 운영체제는 더 많은 프로세스를 메모리에 올리는 과정의 악순환
- 해결법
  - 메모리 늘리기
  - HDD 사용중이라면 SDD로 바꾸기
  - 운영체제에서: 작업세트, PFF

### 작업 세트(working set)
- 프로세스의 과거 사용 이력인 지역성(locality)를 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
- 탐색에 드는 비용과 스와핑을 줄일 수 있다.

### PFF(Page Fault Frequency)
- 페이지 폴트 빈도를 조절하는 방법으로, 상한선과 하한선을 만든다.
- (페이지 폴트 빈도의) 상한선에 도달하면 페이지를 늘리고, 하한선에 도달하면 페이지를 줄인다.

## 메모리 할당
메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 한다. 연속 할당과 불연속 할당으로 나뉜다

### 연속 할당
> 메모리에 연속적으로 공간을 할당하는 것
- 각각의 프로세스들을 묶어서 할당한다.
- 고정 분할 방식과 가변 분할 방식으로 나뉜다.
  #### 고정 분할 방식(fixed partition allocation)
  - 메모리를 미리 나누어 관리하는 방식
  - 융통성이 없고 내부 단편화가 발생한다.
    - `내부 단편화(internal fragmentation)`: 메모리를 나눈 크기보다 프로그램이 작아서, 남는 공간이 많이 생기는 현상
  #### 가변 분할 방식(variable partition allocation)
  - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용한다.
  - 내부 단편화는 발생하지 않고, 외부 단편화가 발생한다.
    - `외부 단편화(external fragmentation)`
      - 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 생기는 현상. 
  - 종류
    |이름|설명|
    |---|---|
    |최초적합(first fit)|위쪽이나 아래쪽에서 시작해서 홀을 찾으면 바로 할당
    |최적적합(best fit)|프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당|
    |최악적합(worst fit|프로세스의 크기와 가장 많이 차이나는 홀에 할당한다.|
    - `홀(hole)`: 할당할 수 있는 비어있는 메모리 공간

### 연속 할당
> 메모리에 불연속적으로 공간을 할당하는 것
- 현대 운영체제가 쓰는 방법.
- 페이징 기법, 세그멘테이션, 페이지드 세그멘테이션 등이 있다.
  #### 페이징(paging)
  - 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당함
  - 홀의 크기가 균일해지지만 주소 변환이 복잡해진다. 
  #### 세그멘테이션(segmentation)
  - 페이지처럼 크기 단위가 아닌 의미 단위인 세그먼트(segment)로 나누는 방식
  - 프로세스는 코드, 데이터, 스택, 힙 등으로 이루어짐
    - 코드와 데이터 등을 기반으로 하거나 함수 단위로 나눌 수도 있다.
  - 공유와 보안 측면에서 장점
  - 홀 크기가 균일하지 않은 문제 발생
  #### 페이지드 세그멘테이션(paged segmentation)
  - 공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것

## 페이지 교체 알고리즘
페이지 교체 알고리즘을 기반으로 스와핑이 일어난다. 최대한 많이 일어나지 않도록 설계되어야 한다.

### 오프라인 알고리즘(offline algorithm)
- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
- 최선의 방법이지만 구현할 수 없다. 하지만 다른 알고리즘과의 성능 비교를 할 때 기준이 된다.

### FIFO(First In First Out)
- 먼저 들어온 순서대로 페이지를 교체하는 방법

### LRU(Least Recently Used)
- 가장 오래 참조되지 않는 페이지를 교체한다.
- 단점: 오래된 페이지를 구분하기 위해 각 페이지마다 계수기, 스택을 둬야한다.
- 프로그래밍으로 LRU를 구현할 때는 보통 해시 테이블과 이중 연결 리스트를 쓴다.
  - 해시 테이블: 이중 연결 리스트에서 빠르게 찾기
  - 이중 연결 리스트: 한정된 메모리를 나타냄

### NUR(Not Used Recently)
- LRU에서 발전한 알고리즘.
- clock 알고리즘이라고도 한다.
  - 0과 1을 가진 비트를 둔다. 1은 최근에 참조됨을, 0은 참조되지 않음을 의미
  - 시계 방향으로 돌면서 0을 찾고, 찾은 순간 해당 프로세스를 교체한다. 그리고 1로 바꾼다.

### LFU(Least Frequently Used)
- 가장 참조 횟수가 적은 페이지를 교체한다.

<br>

# 3.3 프로세스와 스레드
- 프로세스(process)
  - 컴퓨터에서 실행되고 있는 프로그램.
  - CPU 스케줄링의 대상이 되는 작업(task)이라는 용어와 거의 같은 의미로 쓰인다.
  - HDD/SSD에 있던 프로그램이 메모리에 올라가면 프로세스가 된다(인스턴스화). 이후 운영체제의 CPU 스케줄러에 따라 CPU가 프로세스를 실행한다.
- 스레드: 프로세스 내 작업의 흐름을 지칭함

# 3.3.1 프로세스와 컴파일 과정
- 프로세스: 프로그램으로부터 인스턴스화된 것
  - ex) 프로그램은 chrome.exe와 같은 실행파일, 이를 두 번 클릭하면 구글 크롬 프로세스가 시작된다.
- 프로그램: 컴파일 과정을 거쳐 컴퓨터가 이해할 수 있는 기계어로 번역되어 실행할 수 있는 파일이 된 것
  - 여기서 말하는 프로그램은 C언어 기반의 프로그램이다. 인터프리터 언어(파이썬 등)로된 프로그램과는 다름

## 전처리
- 소스 코드의 주석을 제거하고 #include 등 헤더 파일을 병합하여 매크로를 치환한다.

## 컴파일러
- 오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환한다.

## 어셈블러
- 어셈블리어가 목적 코드(object code)로 변환된다.
- 이 때 확장자는 운영체제마다 다른데, 리눅스에서는 .o가 된다.

## 링커
- 프로그램 내에 있는 랑리브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만든다.
- 실행 파일의 확장자는 .exe 또는 .out이다.

  ### 정적 라이브러리와 동적 라이브러리
  - 정적 라이브러리
    - 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식.
    - 장점: 시스템 환경 등 외부 의존도가 낮다.
    - 단점: 코드 중복 등 메모리 효율성이 떨어진다.
  - 동적 라이브러리
    - 프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하는 방식
    - 장점: 메모리 효율성
    - 단점: 외부 의존도가 높아진다.

<br>

# 3.3.2 프로세스의 상태
## 생성 상태(create)
- 프로세스가 생성된 상태
- fork() 또는 exec() 함수를 통해 생성한다. 이때 PCB가 할당된다.
### fork()
- 부모 프로세스의 주소 공간을 그대로 복사하여 새로운 자식 프로세스를 생성하는 함수
- 부모 프로세스의 비동기 작업 등은 상속하지 않는다.
### exec()
- 새로운 프로세스를 생성하는 함수

## 대기 상태(ready)
- CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태
- 메모리 공간이 충분하면 메모리를 할당받고, 아니라면 대기하고 있음

## 대기 중단 상태(ready suspended)
- 메모리 부족으로 일지 중단된 상태

## 실행 상태(running)
- CPU 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태 (CPU burst가 일어났다고도 표현함)

## 중단 상태(blocked)
- 어떤 이벤트가 발생한 이후 기다리며 프로세스가 차단된 상태
- I/O 디바이스에 의한 인터럽트로 많이 발생한다. (예를 들어 프린트 인쇄 버튼을 눌렀을 때)

## 일시 중단 상태(blocked suspended)
- 중단된 상태에서 프로세스가 실행되려고 했지만 메모리 부족으로 일시 중단된 상태
- 대기 중단 상태와 유사하다.

## 종료 상태(terminated)
- 메모리와 CPU 소유권을 모두 놓고 가는 상태
- 발생하는 상황
  1. 자연스럽게 종료됨
  2. 부모 프로세스가 자식 프로세스를 강제로 종료시키는 비자발적 종료(abort)
      - 자식 프로세스에 할당된 자원의 한계치를 넘어섰을 때
      - 부모 프로세스가 종료됐을 때
      - 사용자가 process.kill 등의 명령어로 프로세스를 종료할 때

<br>

# 3.3.3 프로세스의 메모리 구조
운영체제는 프로세스에 적절한 메모리를 할당한다. 이는 다음 구조를 기반으로 한다.

|프로세스의 메모리 구조|
|---|
|스택|
|힙|
|데이터 영역|
|코드 영역|

- 동적 영역: 스택, 힙
- 정적 영역: 데이터 영역, 코드 영역
- 스택은 위 주소부터, 힙은 아래 주소부터 할당된다.

## 스택(stack)
- 지역변수, 매개변수, 함수가 저장된다,
- 컴파일 시 크기가 결정되며 동적인 특징을 가짐
- 함수가 함수를 재귀적으로 호출하면서 스택 영역의 크기가 동적으로 늘어날 수 있다. 이때 힙과 스택은 메모리 영역이 겹치면 안되기 때문에, 힙과 스택 사이의 공간을 비워놓는다.

## 힙(heap)
- 런타임 시 크기가 결정되며 동적 할당할 때 쓰인다.
- 벡터 같은 동적 배열은 힙에 동적 할당된다.

## 데이터 영역
- 전역변수, 정적변수가 저장된다. 정적인 특성을 갖는 프로그램이 종료되면 사라지는 변수가 들어있는 영역이다.
- 두 영역으로 나뉜다.
  - BSS 영역(BSS segment): 초기화되지 않은 변수들이 0으로 초기화되어 저장됨
  - Data 영역(Data segment): 0이 아닌 다른 값이 할당된 변수들이 저장됨

## 코드 영역(code segment)
- 프로그램에 내장되어 있는 소스 코드가 들어가는 정적인 영역
- 소스 코드가 수정 불가능한 기계어로 저장되어 있다.

# 3.3.4 PCB(Process Control Block)
- 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터. 프로세스가 생성되면 운영체제가 PCB를 생성한다.
  - `메타데이터`
    - 데이터에 관한 구조화된 데이터이자 데이터를 설명하는 작은 데이터.
    - 대량의 정보 가운데에서 정보를 효율적으로 찾아내기 위해 일정한 규칙에 따라 콘텐츠에 부여되는 데이터.
- 프로세스 제어 블록
- 프로세스의 중요한 정보를 포함하고 있기 때문에 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리된다.

## PCB의 구조
1. 프로세스 스케줄링 상태: '준비', '일시중단' 등 프로세스가 CPU에 대한 소유권을 얻은 이후의 상태
2. 프로세스 ID: 프로세스 ID와 해당 프로세스의 자식 프로세스 ID
3. 프로세스 권한: 컴퓨터 자원 또는 I/O 디바이스에 대한 권한 정보
4. 프로그램 카운터: 프로세스에서 실행해야 할 다음 명령어의 주소에 대한 포인터
5. CPU 레지스터: 프로세스를 실행하기 위해 저장해야 할 레지스터에 대한 정보
6. CPU 스케줄링 정보: CPU 스케줄러에 의해 중단된 시간 등에 대한 정보
7. 계정 정보: 프로세스 실행에 사용된 CPU 사용량, 실행한 유저의 정보
8. I/O 상태 정보: 프로세스에 할당된 I/O 디바이스 목록

## 컨텍스트 스위칭(context switching)
- 한 프로세스에 할당된 시간이 끝나거나 인터럽트가 발생했을 때, PCB를 교환하는 과정
- 싱글 코어 CPU 컴퓨터에서는 한 시점에서 실행되는 프로세스는 단 한개이다. 
- 프로세스 A가 실행하다 멈춤 -> 프로세스 A의 PCB를 저장 -> 프로세스 B를 로드하여 실행 -> 반복
- 유휴 시간(idle time): 컨텍스트 스위칭에 드는 비용 중 하나. `프로세스 A의 PCB를 저장 -> 프로세스 B를 로드하여 실행` 하는 시간.

### 컨텍스트 스위칭에 드는 비용: 캐시미스
- 컨텍스트 스위칭이 일어날 때 프로세스가 가지고 있는 메모리 주소가 그대로 있으면 잘못된 주소 변환이 생긴다. 이때 캐시클리어 과정이 생기고, 이 때문에 캐시미스가 발생한다.

### 스레드에서의 컨텍스트 스위칭
- 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에, 스레드의 컨텍스트 스위칭의 경우 비용이 더 적고 시간도 더 적게 걸린다.

<br>

# 3.3.5 멀티프로세싱
- 여러 개의 프로세스(멀티프로세스)를 통해 동시에 두 가지 이상의 일을 병렬로 수행할 수 있는 것
- 일부 프로세스에 문제가 생기더라도 다른 프로세스를 이용해서 처리할 수 있으므로 신뢰성이 높다.

## 웹 브라우저
- 웹 브라우저는 다음과 같은 멀티프로세스 구조를 가지고 있다.
1. 브라우저 프로세스: 주소 표시줄, 북마크 막대, 뒤로, 앞으로 가기 버튼 등을 담당함. 네트워크 요청이나 파일 접근 같은 권한 또한 담당
2. 렌더러 프로세스: 웹 사이트가 보이는 부분의 모든 것을 제어함
3. 플러그인 프로세스: 웹 사이트에서 사용하는 플러그인을 제어함
4. GPU 프로세스: GPU를 사용해서 화면을 그리는 부분을 제어함

## IPC(Inter Process Communication)
- 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘
- 멀티프로세스는 IPC가 가능하다.
- 메모리가 완전히 공유되는 스레드보다는 속도가 떨어진다.
- 예시) 클라이언트가 데이터를 요청하고, 서버가 클라이언트의 요청에 응답하는 것

### 공유 메모리(shared memory)
- 여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어, 프로세스가 서로 통신할 수 있도록 공유 버퍼를 생성하는 것
- 기본적으로 각 프로세스의 메모리를 다른 프로세스가 접근할 수 없다. 공유 메모리를 사용하면 여러 프로세스가 하나의 메모리를 공유할 수 있게 된다.
- IPC 중에서도, 어떤 매개체를 통해 데이터를 주고받는 것이 아니라 메모리 자체를 공유하기 때문에
  - 불필요한 데이터 복사의 오버헤드가 발생하지 않아 가장 빠르다.
  - 공유하는 메모리 영역의 동기화가 필요하다.
- 하드웨어 관점에서 공유 메모리는 RAM(CPU가 접근할 수 있는 가장 큰 랜덤 접근 메모리)을 가리키기도 한다.

### 파일
- 디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터. 이를 기반으로 프로세스 간 통신을 한다.

### 소켓
- 동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터
- TCP, UDP가 있다.

### 익명 파이프(unnamed pipe)
- 프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고받으며, 단방향 방식의 읽기 전용, 쓰기 전용 파이프를 만들어 작동하는 방식
- 부모, 자식 프로세스 간에만 사용할 수 있다. 다른 네트워크 상에서는 사용 불가

### 명명된 파이프(named pipe)
- 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 단방향 또는 이중 파이프
- 클라이언트/서버 통신을 위한 별도의 파이프를 제공하며, 여러 파이프를 동시에 사용할 수도 있다.
- 컴퓨터의 프로세스 끼리, 다른 네트워크 상의 컴퓨터와도 통신할 수 있다.
- 서버용 파이프, 클라이언트용 파이프로 구분해서 작동함.
- 인스턴스를 한 개 또는 여러 개 생성해서 통신한다.

### 메시지 큐
- 메시지를 큐 데이터 구조로 관리하는 것
- 커널에서 전역적으로 관리된다.
- 다른 IPC 방식에 비해서 사용방법이 직관적이며 간단하다. 다른 코드의 수정 없이 몇 줄의 코드를 추가시키면 메시지 큐에 접근할 수 있다.
- 공유 메모리의 대안으로 메시지 큐를 사용하기도 한다. 공유 메모리에서 쓰기 및 읽기 빈도가 높으면 동기화 때문에 기능 구현이 복잡해지기 때문이다.

<br>

# 3.3.6 스레드와 멀티스레딩
## 스레드
> 프로세스의 실행 가능한 가장 작은 단위. 프로세스는 여러 스레드를 가질 수 있다.
- 프로세스는 코드, 데이터, 스택, 힙을 각각 생성하지만, 스레드는 스택을 제외한 코드, 데이터, 힙을 스레드끼리 공유한다.

## 멀티스레딩
> 프로세스 내 작업을 여러 개의 스레드(멀티스레드)로 처리하는 기법.
- 스레드끼리 자원을 공유하기 때문에 효율성이 높다.
- 장점
  - 새 프로세스를 생성하는 대신 스레드를 사용하면 훨씬 적은 리소스를 소비한다.
  - 한 스레드가 중단(blocked)되어도 다른 스레드는(running) 상태일 수 있기 때문에, 중단되지 않고 빠르게 처리 가능
  - 동시성에도 장점
    - `동시성`: 서로 독립적인 작업들을 작은 단위로 나누고 동시에 실행되는 것처럼 보여주는 것
- 단점
  - 한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐, 프로세스에 영향을 줄 수 있다.
- 예시) 웹 브라우저의 렌더러 프로세스
  - 이 프로세스 내에는 메인 스레드, 워커 스레드, 컴포지터 스레드, 레스터 스레드가 있다.

